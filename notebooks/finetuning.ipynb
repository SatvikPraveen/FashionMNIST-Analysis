{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf544ea-0674-44a3-9621-32a74ecaf9f6",
   "metadata": {},
   "source": [
    "# Finetuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5411ca-90ad-45ac-b845-bf19ba093da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7ba75a-0c29-4620-a024-15a183b6953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dc3aa3-f1b2-49a9-bbcc-a4b61dfe05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Define device (use \"cuda\" if available, otherwise \"cpu\" or \"mps\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451e3df4-bd3e-44cc-b530-15423ada5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src folder to the Python path\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa2754-afe3-49d7-ac54-e94f099c43e0",
   "metadata": {},
   "source": [
    "## Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f02802b-a885-4af3-b642-8190d1eeee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data loading completed successfully!\n",
      "Training samples: 48000\n",
      "Validation samples: 12000\n",
      "Test samples: 10000\n",
      "Sample image shape: torch.Size([1, 28, 28]), Sample label: 1\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the number of epochs for fine-tuning\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Set the number of classes for the classification task\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Define the paths for the preprocessed CSV files\n",
    "csv_dir = \"../data_preparation\"\n",
    "train_csv_path = os.path.join(csv_dir, \"train_data.csv\")\n",
    "validation_csv_path = os.path.join(csv_dir, \"validation_data.csv\")\n",
    "test_csv_path = os.path.join(csv_dir, \"test_data.csv\")\n",
    "\n",
    "# Function to load CSV data into a TensorDataset\n",
    "def load_csv_to_dataset(csv_path):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a PyTorch TensorDataset.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        TensorDataset: A dataset containing features and labels as tensors.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = torch.tensor(df.iloc[:, 0].values, dtype=torch.long)\n",
    "    features = torch.tensor(df.iloc[:, 1:].values, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
    "    return TensorDataset(features, labels)\n",
    "\n",
    "# Load datasets\n",
    "train_data = load_csv_to_dataset(train_csv_path)\n",
    "validation_data = load_csv_to_dataset(validation_csv_path)\n",
    "test_data = load_csv_to_dataset(test_csv_path)\n",
    "\n",
    "print(\"\\n✅ Data loading completed successfully!\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(validation_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Quick data check\n",
    "sample_img, sample_label = train_data[0]\n",
    "print(f\"Sample image shape: {sample_img.shape}, Sample label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e0e25-034e-426b-8a36-f3f28a1480d2",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a353c446-be4e-4ff1-b018-bb6a02323c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 28, 28]), Labels batch shape: torch.Size([32])\n",
      "\n",
      "✅ Hyperparameter tuning setup completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning Grid Setup\n",
    "\n",
    "# Define possible batch sizes to explore\n",
    "BATCH_SIZES = [32, 64]\n",
    "# BATCH_SIZES = [32, 64, 128]\n",
    "\n",
    "# Define learning rates to try for fine-tuning\n",
    "LEARNING_RATES = [1e-5, 5e-6]\n",
    "#LEARNING_RATES = [1e-5, 5e-6, 1e-6]\n",
    "\n",
    "# Define patience values for early stopping\n",
    "PATIENCE_VALUES = [2, 3]\n",
    "#PATIENCE_VALUES = [2, 3, 5]\n",
    "\n",
    "# Function to create DataLoaders with a specified batch size\n",
    "def create_dataloaders(batch_size):\n",
    "    \"\"\"\n",
    "    Creates DataLoaders for training, validation, and test datasets.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Batch size for the DataLoaders.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of DataLoaders (train_loader, val_loader, test_loader).\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Test DataLoader creation with the default batch size of 32\n",
    "default_batch_size = 32\n",
    "train_loader, val_loader, test_loader = create_dataloaders(batch_size=default_batch_size)\n",
    "\n",
    "# Quick check for one batch of training data\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features_batch.shape}, Labels batch shape: {train_labels_batch.shape}\")\n",
    "\n",
    "# Initialize a dictionary to store results of all hyperparameter configurations\n",
    "tuning_results = {}\n",
    "\n",
    "print(\"\\n✅ Hyperparameter tuning setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e7c51-5adc-4a40-9d84-9beb0e49fc28",
   "metadata": {},
   "source": [
    "## Loading Pre-Trained Models for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b23a87f-8b9a-4ecb-b33e-53115795d7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Optimizer set up with learning rate: 1e-05\n",
      "🔧 Optimizer set up with learning rate: 1e-05\n",
      "🔧 Optimizer set up with learning rate: 1e-06\n",
      "\n",
      "[INFO] Pre-trained models and optimizers are ready for fine-tuning.\n",
      "Mini CNN model: MiniCNN(\n",
      "  (conv_block): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=1568, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Tiny VGG model: TinyVGG(\n",
      "  (conv_block_1): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_2): Sequential(\n",
      "    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=980, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "ResNet model: ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Define the directory where pre-trained models are saved\n",
    "models_dir = \"../models/all_models\"\n",
    "\n",
    "# Function to load a model and its weights\n",
    "# Function to load a model and its weights\n",
    "def load_model(model_class, model_name, in_channels=1, num_classes=NUM_CLASSES, hidden_units=20):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model and its weights using the state dictionary.\n",
    "\n",
    "    Args:\n",
    "        model_class: The class of the model to be loaded (e.g., MiniCNN, TinyVGG, ResNet).\n",
    "        model_name (str): Name of the model file (without extension).\n",
    "        in_channels (int): Number of input channels (default is 1 for grayscale images).\n",
    "        num_classes (int): Number of output classes.\n",
    "        hidden_units (int): Number of hidden units (used for TinyVGG).\n",
    "\n",
    "    Returns:\n",
    "        model: The loaded model instance with weights.\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(models_dir, f\"{model_name}_weights.pth\")\n",
    "    \n",
    "    # Initialize the model based on its class\n",
    "    if model_class == MiniCNN:\n",
    "        model = model_class(in_channels=in_channels, num_classes=num_classes)\n",
    "    elif model_class == TinyVGG:\n",
    "        model = model_class(in_channels=in_channels, hidden_units=hidden_units, num_classes=num_classes)\n",
    "    elif model_class == ResNet:\n",
    "        model = model_class(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model class: {model_class}\")\n",
    "\n",
    "    # Load the state dictionary\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"✅ {model_name} loaded successfully from: {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the Mini CNN model\n",
    "from model_definitions import MiniCNN\n",
    "mini_cnn_model = load_model(MiniCNN, \"mini_cnn_model\")\n",
    "\n",
    "# Load the Tiny VGG model\n",
    "from model_definitions import TinyVGG\n",
    "tiny_vgg_model = load_model(TinyVGG, \"tiny_vgg_model\")\n",
    "\n",
    "# Load the ResNet model\n",
    "from model_definitions import ResNet, BasicBlock\n",
    "resnet_model = load_model(ResNet, \"resnet_model\")\n",
    "\n",
    "# Define a function to create an optimizer with a smaller learning rate for fine-tuning\n",
    "def setup_optimizer(model, learning_rate):\n",
    "    \"\"\"\n",
    "    Sets up an Adam optimizer for a given model with a specified learning rate.\n",
    "\n",
    "    Args:\n",
    "        model: The model to optimize.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        optimizer: A PyTorch Adam optimizer instance.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"🔧 Optimizer set up with learning rate: {learning_rate}\")\n",
    "    return optimizer\n",
    "\n",
    "# Setup optimizers for each model with a smaller learning rate for fine-tuning\n",
    "mini_cnn_optimizer = setup_optimizer(mini_cnn_model, learning_rate=1e-5)\n",
    "tiny_vgg_optimizer = setup_optimizer(tiny_vgg_model, learning_rate=1e-5)\n",
    "resnet_optimizer = setup_optimizer(resnet_model, learning_rate=1e-6)\n",
    "\n",
    "# Quick summary of models and optimizers\n",
    "print(\"\\n[INFO] Pre-trained models and optimizers are ready for fine-tuning.\")\n",
    "print(f\"Mini CNN model: {mini_cnn_model}\")\n",
    "print(f\"Tiny VGG model: {tiny_vgg_model}\")\n",
    "print(f\"ResNet model: {resnet_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6b207-af40-4b6b-9099-9bd59e882e8b",
   "metadata": {},
   "source": [
    "### Fine-Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c109b430-f5bc-4645-9344-9d702eae11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def fine_tune_model(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    val_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    patience: int = 3,\n",
    "    min_delta: float = 0.001,\n",
    "    unfreeze_layers: bool = False\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Fine-tunes a PyTorch model with optional unfreezing of layers.\n",
    "\n",
    "    Args:\n",
    "        model: The model to be fine-tuned.\n",
    "        train_dataloader: DataLoader for the training data.\n",
    "        val_dataloader: DataLoader for the validation data.\n",
    "        test_dataloader: DataLoader for the test data.\n",
    "        optimizer: Optimizer for minimizing the loss.\n",
    "        loss_fn: Loss function to use.\n",
    "        epochs: Maximum number of epochs for fine-tuning.\n",
    "        device: Device for computations (e.g., \"cuda\" or \"cpu\").\n",
    "        patience: Number of epochs to wait for improvement before early stopping.\n",
    "        min_delta: Minimum change in validation loss to qualify as an improvement.\n",
    "        unfreeze_layers: Whether to unfreeze certain layers of the model.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing training, validation, and testing metrics.\n",
    "    \"\"\"\n",
    "    # Unfreeze certain layers if specified\n",
    "    if unfreeze_layers:\n",
    "        print(\"\\n🔓 Unfreezing certain layers for fine-tuning...\")\n",
    "        if isinstance(model, ResNet):\n",
    "            for param in model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif isinstance(model, TinyVGG):\n",
    "            for param in model.conv_block_2.parameters():\n",
    "                param.requires_grad = True\n",
    "        print(\"✅ Layers unfrozen successfully.\")\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\": [], \"val_acc\": [],\n",
    "        \"test_loss\": [], \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Initialize early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_weights = model.state_dict()\n",
    "\n",
    "    # Loop through epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training step\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "\n",
    "        # Validation step\n",
    "        val_loss, val_acc = validation_step(model, val_dataloader, loss_fn, device)\n",
    "\n",
    "        # Testing step\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, device)\n",
    "\n",
    "        # Print epoch metrics\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "            f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Store metrics\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict()\n",
    "            counter = 0\n",
    "            print(\"✅ Improvement in validation loss. Best model weights updated.\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"No improvement in validation loss. Early stopping counter: {counter}/{patience}\")\n",
    "\n",
    "        # Check if early stopping should be triggered\n",
    "        if counter >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered at epoch {epoch + 1}.\")\n",
    "            break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1bc511-ca7d-4270-9797-76aaff5ae2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Tuning with Batch Size: 32, Learning Rate: 1e-05, Patience: 2\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb39d1a7294cca9f51bec0586c6add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1478 | Train Acc: 0.9464 | Val Loss: 0.2229 | Val Acc: 0.9196 | Test Loss: 0.2513 | Test Acc: 0.9113\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1408 | Train Acc: 0.9492 | Val Loss: 0.2213 | Val Acc: 0.9216 | Test Loss: 0.2503 | Test Acc: 0.9124\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1385 | Train Acc: 0.9500 | Val Loss: 0.2208 | Val Acc: 0.9217 | Test Loss: 0.2503 | Test Acc: 0.9130\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.1369 | Train Acc: 0.9501 | Val Loss: 0.2205 | Val Acc: 0.9215 | Test Loss: 0.2500 | Test Acc: 0.9131\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 4.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs32_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c1e13789e14ea4bb41456efc2e8bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1731 | Train Acc: 0.9375 | Val Loss: 0.2264 | Val Acc: 0.9197 | Test Loss: 0.2516 | Test Acc: 0.9096\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1645 | Train Acc: 0.9416 | Val Loss: 0.2240 | Val Acc: 0.9207 | Test Loss: 0.2496 | Test Acc: 0.9115\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1617 | Train Acc: 0.9425 | Val Loss: 0.2230 | Val Acc: 0.9207 | Test Loss: 0.2486 | Test Acc: 0.9115\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.1600 | Train Acc: 0.9431 | Val Loss: 0.2223 | Val Acc: 0.9207 | Test Loss: 0.2483 | Test Acc: 0.9113\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1586 | Train Acc: 0.9437 | Val Loss: 0.2217 | Val Acc: 0.9210 | Test Loss: 0.2477 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 6 | Train Loss: 0.1575 | Train Acc: 0.9441 | Val Loss: 0.2213 | Val Acc: 0.9207 | Test Loss: 0.2474 | Test Acc: 0.9123\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 6.\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs32_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34b044c3d114dbbb695a1541fd4d6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.0932 | Train Acc: 0.9659 | Val Loss: 0.1832 | Val Acc: 0.9358 | Test Loss: 0.2089 | Test Acc: 0.9264\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0780 | Train Acc: 0.9721 | Val Loss: 0.1806 | Val Acc: 0.9376 | Test Loss: 0.2045 | Test Acc: 0.9290\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0714 | Train Acc: 0.9750 | Val Loss: 0.1834 | Val Acc: 0.9376 | Test Loss: 0.2091 | Test Acc: 0.9288\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.0667 | Train Acc: 0.9756 | Val Loss: 0.1821 | Val Acc: 0.9386 | Test Loss: 0.2072 | Test Acc: 0.9311\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 4.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs32_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 32, Learning Rate: 1e-05, Patience: 3\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6072cd5a77480bb7ebd2d610695019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1476 | Train Acc: 0.9461 | Val Loss: 0.2226 | Val Acc: 0.9203 | Test Loss: 0.2511 | Test Acc: 0.9125\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1408 | Train Acc: 0.9491 | Val Loss: 0.2213 | Val Acc: 0.9212 | Test Loss: 0.2505 | Test Acc: 0.9128\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1385 | Train Acc: 0.9496 | Val Loss: 0.2207 | Val Acc: 0.9216 | Test Loss: 0.2500 | Test Acc: 0.9125\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 4 | Train Loss: 0.1369 | Train Acc: 0.9504 | Val Loss: 0.2202 | Val Acc: 0.9220 | Test Loss: 0.2500 | Test Acc: 0.9136\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1357 | Train Acc: 0.9508 | Val Loss: 0.2198 | Val Acc: 0.9225 | Test Loss: 0.2498 | Test Acc: 0.9136\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 6 | Train Loss: 0.1348 | Train Acc: 0.9509 | Val Loss: 0.2197 | Val Acc: 0.9227 | Test Loss: 0.2495 | Test Acc: 0.9145\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 7 | Train Loss: 0.1340 | Train Acc: 0.9510 | Val Loss: 0.2196 | Val Acc: 0.9222 | Test Loss: 0.2496 | Test Acc: 0.9144\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs32_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c308a93534ec42ad87bd8c9fed70ab06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1730 | Train Acc: 0.9376 | Val Loss: 0.2264 | Val Acc: 0.9192 | Test Loss: 0.2516 | Test Acc: 0.9103\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1645 | Train Acc: 0.9415 | Val Loss: 0.2237 | Val Acc: 0.9210 | Test Loss: 0.2492 | Test Acc: 0.9104\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1618 | Train Acc: 0.9422 | Val Loss: 0.2226 | Val Acc: 0.9204 | Test Loss: 0.2484 | Test Acc: 0.9115\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1600 | Train Acc: 0.9427 | Val Loss: 0.2222 | Val Acc: 0.9207 | Test Loss: 0.2481 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.1587 | Train Acc: 0.9435 | Val Loss: 0.2215 | Val Acc: 0.9203 | Test Loss: 0.2473 | Test Acc: 0.9114\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1575 | Train Acc: 0.9440 | Val Loss: 0.2211 | Val Acc: 0.9205 | Test Loss: 0.2470 | Test Acc: 0.9121\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 7 | Train Loss: 0.1566 | Train Acc: 0.9449 | Val Loss: 0.2210 | Val Acc: 0.9207 | Test Loss: 0.2471 | Test Acc: 0.9127\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 8 | Train Loss: 0.1558 | Train Acc: 0.9446 | Val Loss: 0.2205 | Val Acc: 0.9209 | Test Loss: 0.2464 | Test Acc: 0.9123\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 9 | Train Loss: 0.1551 | Train Acc: 0.9451 | Val Loss: 0.2206 | Val Acc: 0.9212 | Test Loss: 0.2466 | Test Acc: 0.9131\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 10 | Train Loss: 0.1544 | Train Acc: 0.9454 | Val Loss: 0.2201 | Val Acc: 0.9205 | Test Loss: 0.2459 | Test Acc: 0.9130\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs32_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c3e3eae0e24f0e8867bbc8e140a910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.0933 | Train Acc: 0.9664 | Val Loss: 0.1827 | Val Acc: 0.9354 | Test Loss: 0.2082 | Test Acc: 0.9268\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0778 | Train Acc: 0.9723 | Val Loss: 0.1824 | Val Acc: 0.9372 | Test Loss: 0.2075 | Test Acc: 0.9295\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 3 | Train Loss: 0.0711 | Train Acc: 0.9744 | Val Loss: 0.1812 | Val Acc: 0.9383 | Test Loss: 0.2055 | Test Acc: 0.9300\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.0662 | Train Acc: 0.9760 | Val Loss: 0.1827 | Val Acc: 0.9382 | Test Loss: 0.2071 | Test Acc: 0.9308\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.0623 | Train Acc: 0.9781 | Val Loss: 0.1835 | Val Acc: 0.9390 | Test Loss: 0.2078 | Test Acc: 0.9311\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 6 | Train Loss: 0.0591 | Train Acc: 0.9792 | Val Loss: 0.1853 | Val Acc: 0.9397 | Test Loss: 0.2104 | Test Acc: 0.9323\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 6.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs32_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 32, Learning Rate: 5e-06, Patience: 2\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834cb0bde3ed494fa2b4dd495944e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1514 | Train Acc: 0.9448 | Val Loss: 0.2246 | Val Acc: 0.9195 | Test Loss: 0.2523 | Test Acc: 0.9118\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1434 | Train Acc: 0.9481 | Val Loss: 0.2227 | Val Acc: 0.9205 | Test Loss: 0.2511 | Test Acc: 0.9127\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1412 | Train Acc: 0.9491 | Val Loss: 0.2218 | Val Acc: 0.9213 | Test Loss: 0.2506 | Test Acc: 0.9128\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.1397 | Train Acc: 0.9496 | Val Loss: 0.2213 | Val Acc: 0.9216 | Test Loss: 0.2503 | Test Acc: 0.9125\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1387 | Train Acc: 0.9498 | Val Loss: 0.2208 | Val Acc: 0.9216 | Test Loss: 0.2501 | Test Acc: 0.9126\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 6 | Train Loss: 0.1377 | Train Acc: 0.9501 | Val Loss: 0.2206 | Val Acc: 0.9213 | Test Loss: 0.2500 | Test Acc: 0.9126\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 6.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs32_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79839013e8304672bdafd957f1a5b004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1777 | Train Acc: 0.9353 | Val Loss: 0.2304 | Val Acc: 0.9180 | Test Loss: 0.2560 | Test Acc: 0.9084\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1680 | Train Acc: 0.9400 | Val Loss: 0.2263 | Val Acc: 0.9203 | Test Loss: 0.2516 | Test Acc: 0.9102\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1650 | Train Acc: 0.9413 | Val Loss: 0.2248 | Val Acc: 0.9204 | Test Loss: 0.2503 | Test Acc: 0.9104\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1632 | Train Acc: 0.9420 | Val Loss: 0.2240 | Val Acc: 0.9210 | Test Loss: 0.2497 | Test Acc: 0.9110\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 5 | Train Loss: 0.1620 | Train Acc: 0.9425 | Val Loss: 0.2233 | Val Acc: 0.9213 | Test Loss: 0.2490 | Test Acc: 0.9112\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1609 | Train Acc: 0.9429 | Val Loss: 0.2228 | Val Acc: 0.9207 | Test Loss: 0.2484 | Test Acc: 0.9114\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 7 | Train Loss: 0.1600 | Train Acc: 0.9428 | Val Loss: 0.2224 | Val Acc: 0.9209 | Test Loss: 0.2482 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs32_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81b9081e5f9449e90e2de0e481c75b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1004 | Train Acc: 0.9639 | Val Loss: 0.1851 | Val Acc: 0.9340 | Test Loss: 0.2109 | Test Acc: 0.9252\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0861 | Train Acc: 0.9683 | Val Loss: 0.1824 | Val Acc: 0.9353 | Test Loss: 0.2080 | Test Acc: 0.9273\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0791 | Train Acc: 0.9714 | Val Loss: 0.1810 | Val Acc: 0.9357 | Test Loss: 0.2069 | Test Acc: 0.9276\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.0753 | Train Acc: 0.9732 | Val Loss: 0.1802 | Val Acc: 0.9376 | Test Loss: 0.2049 | Test Acc: 0.9287\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 5 | Train Loss: 0.0715 | Train Acc: 0.9747 | Val Loss: 0.1819 | Val Acc: 0.9380 | Test Loss: 0.2061 | Test Acc: 0.9292\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 5.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs32_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 32, Learning Rate: 5e-06, Patience: 3\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8627dbee77042858b58f66991c5be6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1513 | Train Acc: 0.9448 | Val Loss: 0.2247 | Val Acc: 0.9196 | Test Loss: 0.2523 | Test Acc: 0.9121\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1434 | Train Acc: 0.9484 | Val Loss: 0.2227 | Val Acc: 0.9203 | Test Loss: 0.2511 | Test Acc: 0.9125\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1412 | Train Acc: 0.9491 | Val Loss: 0.2218 | Val Acc: 0.9211 | Test Loss: 0.2506 | Test Acc: 0.9130\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 4 | Train Loss: 0.1398 | Train Acc: 0.9494 | Val Loss: 0.2213 | Val Acc: 0.9216 | Test Loss: 0.2504 | Test Acc: 0.9128\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1386 | Train Acc: 0.9498 | Val Loss: 0.2209 | Val Acc: 0.9216 | Test Loss: 0.2501 | Test Acc: 0.9128\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 6 | Train Loss: 0.1377 | Train Acc: 0.9502 | Val Loss: 0.2206 | Val Acc: 0.9217 | Test Loss: 0.2501 | Test Acc: 0.9125\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 7 | Train Loss: 0.1369 | Train Acc: 0.9504 | Val Loss: 0.2204 | Val Acc: 0.9216 | Test Loss: 0.2499 | Test Acc: 0.9127\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs32_lr5e-06_pat3.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c95cc8329414069864903b71c090d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1779 | Train Acc: 0.9356 | Val Loss: 0.2305 | Val Acc: 0.9181 | Test Loss: 0.2560 | Test Acc: 0.9080\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1680 | Train Acc: 0.9399 | Val Loss: 0.2263 | Val Acc: 0.9199 | Test Loss: 0.2515 | Test Acc: 0.9099\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1650 | Train Acc: 0.9410 | Val Loss: 0.2247 | Val Acc: 0.9203 | Test Loss: 0.2501 | Test Acc: 0.9106\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1632 | Train Acc: 0.9418 | Val Loss: 0.2238 | Val Acc: 0.9211 | Test Loss: 0.2494 | Test Acc: 0.9113\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.1620 | Train Acc: 0.9424 | Val Loss: 0.2232 | Val Acc: 0.9210 | Test Loss: 0.2489 | Test Acc: 0.9110\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1609 | Train Acc: 0.9429 | Val Loss: 0.2227 | Val Acc: 0.9203 | Test Loss: 0.2484 | Test Acc: 0.9115\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 7 | Train Loss: 0.1600 | Train Acc: 0.9429 | Val Loss: 0.2224 | Val Acc: 0.9206 | Test Loss: 0.2481 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 8 | Train Loss: 0.1593 | Train Acc: 0.9434 | Val Loss: 0.2221 | Val Acc: 0.9206 | Test Loss: 0.2478 | Test Acc: 0.9117\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 9 | Train Loss: 0.1586 | Train Acc: 0.9436 | Val Loss: 0.2218 | Val Acc: 0.9206 | Test Loss: 0.2477 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 10 | Train Loss: 0.1580 | Train Acc: 0.9439 | Val Loss: 0.2217 | Val Acc: 0.9208 | Test Loss: 0.2477 | Test Acc: 0.9120\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs32_lr5e-06_pat3.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14498f08e0d240149a32e0c778270cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1006 | Train Acc: 0.9635 | Val Loss: 0.1864 | Val Acc: 0.9342 | Test Loss: 0.2116 | Test Acc: 0.9253\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0852 | Train Acc: 0.9699 | Val Loss: 0.1821 | Val Acc: 0.9357 | Test Loss: 0.2066 | Test Acc: 0.9281\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0792 | Train Acc: 0.9721 | Val Loss: 0.1816 | Val Acc: 0.9364 | Test Loss: 0.2067 | Test Acc: 0.9280\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 4 | Train Loss: 0.0752 | Train Acc: 0.9732 | Val Loss: 0.1814 | Val Acc: 0.9370 | Test Loss: 0.2060 | Test Acc: 0.9294\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 5 | Train Loss: 0.0723 | Train Acc: 0.9743 | Val Loss: 0.1812 | Val Acc: 0.9381 | Test Loss: 0.2065 | Test Acc: 0.9291\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 5.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs32_lr5e-06_pat3.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 64, Learning Rate: 1e-05, Patience: 2\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe4ec77b1f144ccadae0ce4218c6fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1498 | Train Acc: 0.9453 | Val Loss: 0.2236 | Val Acc: 0.9195 | Test Loss: 0.2519 | Test Acc: 0.9111\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1422 | Train Acc: 0.9486 | Val Loss: 0.2219 | Val Acc: 0.9211 | Test Loss: 0.2508 | Test Acc: 0.9121\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1400 | Train Acc: 0.9494 | Val Loss: 0.2211 | Val Acc: 0.9214 | Test Loss: 0.2503 | Test Acc: 0.9120\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.1384 | Train Acc: 0.9500 | Val Loss: 0.2206 | Val Acc: 0.9218 | Test Loss: 0.2500 | Test Acc: 0.9122\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1372 | Train Acc: 0.9504 | Val Loss: 0.2203 | Val Acc: 0.9216 | Test Loss: 0.2499 | Test Acc: 0.9133\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 6 | Train Loss: 0.1363 | Train Acc: 0.9504 | Val Loss: 0.2200 | Val Acc: 0.9225 | Test Loss: 0.2498 | Test Acc: 0.9121\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 6.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs64_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648eba7586434a17863de66e5b9c9526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1756 | Train Acc: 0.9364 | Val Loss: 0.2286 | Val Acc: 0.9186 | Test Loss: 0.2536 | Test Acc: 0.9093\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1662 | Train Acc: 0.9407 | Val Loss: 0.2252 | Val Acc: 0.9202 | Test Loss: 0.2500 | Test Acc: 0.9106\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1634 | Train Acc: 0.9418 | Val Loss: 0.2240 | Val Acc: 0.9206 | Test Loss: 0.2488 | Test Acc: 0.9110\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1616 | Train Acc: 0.9425 | Val Loss: 0.2232 | Val Acc: 0.9209 | Test Loss: 0.2484 | Test Acc: 0.9112\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 5 | Train Loss: 0.1603 | Train Acc: 0.9428 | Val Loss: 0.2227 | Val Acc: 0.9209 | Test Loss: 0.2480 | Test Acc: 0.9119\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1592 | Train Acc: 0.9432 | Val Loss: 0.2222 | Val Acc: 0.9206 | Test Loss: 0.2473 | Test Acc: 0.9119\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 7 | Train Loss: 0.1583 | Train Acc: 0.9436 | Val Loss: 0.2219 | Val Acc: 0.9202 | Test Loss: 0.2472 | Test Acc: 0.9120\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs64_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccd4ad61ae840a3a8673250eeab46bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.0935 | Train Acc: 0.9660 | Val Loss: 0.1840 | Val Acc: 0.9355 | Test Loss: 0.2098 | Test Acc: 0.9261\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0793 | Train Acc: 0.9718 | Val Loss: 0.1814 | Val Acc: 0.9371 | Test Loss: 0.2064 | Test Acc: 0.9286\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0724 | Train Acc: 0.9738 | Val Loss: 0.1810 | Val Acc: 0.9377 | Test Loss: 0.2056 | Test Acc: 0.9282\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 4 | Train Loss: 0.0682 | Train Acc: 0.9758 | Val Loss: 0.1821 | Val Acc: 0.9380 | Test Loss: 0.2068 | Test Acc: 0.9293\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 4.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs64_lr1e-05_pat2.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 64, Learning Rate: 1e-05, Patience: 3\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e72c6ec8e0e4f418536ea2b89f5bbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1496 | Train Acc: 0.9457 | Val Loss: 0.2235 | Val Acc: 0.9202 | Test Loss: 0.2519 | Test Acc: 0.9116\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1421 | Train Acc: 0.9489 | Val Loss: 0.2219 | Val Acc: 0.9208 | Test Loss: 0.2508 | Test Acc: 0.9122\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1399 | Train Acc: 0.9495 | Val Loss: 0.2212 | Val Acc: 0.9215 | Test Loss: 0.2504 | Test Acc: 0.9124\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 4 | Train Loss: 0.1384 | Train Acc: 0.9500 | Val Loss: 0.2207 | Val Acc: 0.9218 | Test Loss: 0.2502 | Test Acc: 0.9122\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1372 | Train Acc: 0.9500 | Val Loss: 0.2203 | Val Acc: 0.9219 | Test Loss: 0.2499 | Test Acc: 0.9118\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 6 | Train Loss: 0.1363 | Train Acc: 0.9504 | Val Loss: 0.2201 | Val Acc: 0.9220 | Test Loss: 0.2500 | Test Acc: 0.9131\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 7 | Train Loss: 0.1355 | Train Acc: 0.9507 | Val Loss: 0.2199 | Val Acc: 0.9225 | Test Loss: 0.2498 | Test Acc: 0.9129\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs64_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c1852ff41842ccb64cc32dd866f7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1759 | Train Acc: 0.9359 | Val Loss: 0.2289 | Val Acc: 0.9187 | Test Loss: 0.2539 | Test Acc: 0.9094\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1662 | Train Acc: 0.9404 | Val Loss: 0.2252 | Val Acc: 0.9198 | Test Loss: 0.2501 | Test Acc: 0.9106\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1634 | Train Acc: 0.9418 | Val Loss: 0.2240 | Val Acc: 0.9207 | Test Loss: 0.2488 | Test Acc: 0.9112\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1617 | Train Acc: 0.9426 | Val Loss: 0.2233 | Val Acc: 0.9204 | Test Loss: 0.2483 | Test Acc: 0.9112\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.1603 | Train Acc: 0.9430 | Val Loss: 0.2228 | Val Acc: 0.9209 | Test Loss: 0.2482 | Test Acc: 0.9116\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1592 | Train Acc: 0.9431 | Val Loss: 0.2223 | Val Acc: 0.9205 | Test Loss: 0.2473 | Test Acc: 0.9120\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 7 | Train Loss: 0.1583 | Train Acc: 0.9437 | Val Loss: 0.2218 | Val Acc: 0.9200 | Test Loss: 0.2469 | Test Acc: 0.9114\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 8 | Train Loss: 0.1575 | Train Acc: 0.9442 | Val Loss: 0.2215 | Val Acc: 0.9207 | Test Loss: 0.2468 | Test Acc: 0.9119\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 9 | Train Loss: 0.1569 | Train Acc: 0.9444 | Val Loss: 0.2213 | Val Acc: 0.9204 | Test Loss: 0.2465 | Test Acc: 0.9122\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 10 | Train Loss: 0.1562 | Train Acc: 0.9447 | Val Loss: 0.2212 | Val Acc: 0.9211 | Test Loss: 0.2466 | Test Acc: 0.9127\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 10.\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs64_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 1e-05\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae29b54807c48978370336ecbf88f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.0945 | Train Acc: 0.9662 | Val Loss: 0.1842 | Val Acc: 0.9345 | Test Loss: 0.2097 | Test Acc: 0.9266\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0788 | Train Acc: 0.9719 | Val Loss: 0.1817 | Val Acc: 0.9368 | Test Loss: 0.2070 | Test Acc: 0.9282\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0729 | Train Acc: 0.9737 | Val Loss: 0.1813 | Val Acc: 0.9379 | Test Loss: 0.2062 | Test Acc: 0.9290\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 4 | Train Loss: 0.0687 | Train Acc: 0.9753 | Val Loss: 0.1813 | Val Acc: 0.9378 | Test Loss: 0.2060 | Test Acc: 0.9293\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 5 | Train Loss: 0.0647 | Train Acc: 0.9771 | Val Loss: 0.1820 | Val Acc: 0.9391 | Test Loss: 0.2071 | Test Acc: 0.9312\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 5.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs64_lr1e-05_pat3.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 64, Learning Rate: 5e-06, Patience: 2\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8691c3469cc844959dcff534c0c17db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1543 | Train Acc: 0.9440 | Val Loss: 0.2263 | Val Acc: 0.9186 | Test Loss: 0.2538 | Test Acc: 0.9115\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1450 | Train Acc: 0.9477 | Val Loss: 0.2236 | Val Acc: 0.9201 | Test Loss: 0.2518 | Test Acc: 0.9116\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1427 | Train Acc: 0.9488 | Val Loss: 0.2225 | Val Acc: 0.9210 | Test Loss: 0.2512 | Test Acc: 0.9125\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1413 | Train Acc: 0.9491 | Val Loss: 0.2219 | Val Acc: 0.9216 | Test Loss: 0.2508 | Test Acc: 0.9121\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 5 | Train Loss: 0.1402 | Train Acc: 0.9495 | Val Loss: 0.2214 | Val Acc: 0.9215 | Test Loss: 0.2505 | Test Acc: 0.9125\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1393 | Train Acc: 0.9498 | Val Loss: 0.2211 | Val Acc: 0.9216 | Test Loss: 0.2503 | Test Acc: 0.9123\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 7 | Train Loss: 0.1385 | Train Acc: 0.9497 | Val Loss: 0.2209 | Val Acc: 0.9215 | Test Loss: 0.2503 | Test Acc: 0.9123\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs64_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf03c49570e840e786f90d285d9aade8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1804 | Train Acc: 0.9337 | Val Loss: 0.2337 | Val Acc: 0.9167 | Test Loss: 0.2589 | Test Acc: 0.9069\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1705 | Train Acc: 0.9384 | Val Loss: 0.2287 | Val Acc: 0.9183 | Test Loss: 0.2536 | Test Acc: 0.9093\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1670 | Train Acc: 0.9404 | Val Loss: 0.2264 | Val Acc: 0.9197 | Test Loss: 0.2512 | Test Acc: 0.9102\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1650 | Train Acc: 0.9413 | Val Loss: 0.2253 | Val Acc: 0.9200 | Test Loss: 0.2499 | Test Acc: 0.9109\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1636 | Train Acc: 0.9417 | Val Loss: 0.2246 | Val Acc: 0.9208 | Test Loss: 0.2495 | Test Acc: 0.9108\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 6 | Train Loss: 0.1626 | Train Acc: 0.9418 | Val Loss: 0.2240 | Val Acc: 0.9209 | Test Loss: 0.2489 | Test Acc: 0.9110\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 7 | Train Loss: 0.1618 | Train Acc: 0.9424 | Val Loss: 0.2236 | Val Acc: 0.9213 | Test Loss: 0.2487 | Test Acc: 0.9111\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 8 | Train Loss: 0.1610 | Train Acc: 0.9427 | Val Loss: 0.2232 | Val Acc: 0.9210 | Test Loss: 0.2484 | Test Acc: 0.9117\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 8.\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs64_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0f1d45b3634c80b72acf2f488071d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1004 | Train Acc: 0.9632 | Val Loss: 0.1889 | Val Acc: 0.9335 | Test Loss: 0.2151 | Test Acc: 0.9243\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0867 | Train Acc: 0.9686 | Val Loss: 0.1832 | Val Acc: 0.9357 | Test Loss: 0.2092 | Test Acc: 0.9264\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0805 | Train Acc: 0.9714 | Val Loss: 0.1821 | Val Acc: 0.9361 | Test Loss: 0.2076 | Test Acc: 0.9267\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.0770 | Train Acc: 0.9724 | Val Loss: 0.1822 | Val Acc: 0.9365 | Test Loss: 0.2075 | Test Acc: 0.9280\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 5 | Train Loss: 0.0742 | Train Acc: 0.9734 | Val Loss: 0.1802 | Val Acc: 0.9378 | Test Loss: 0.2045 | Test Acc: 0.9287\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.0708 | Train Acc: 0.9752 | Val Loss: 0.1806 | Val Acc: 0.9377 | Test Loss: 0.2054 | Test Acc: 0.9290\n",
      "No improvement in validation loss. Early stopping counter: 1/2\n",
      "Epoch: 7 | Train Loss: 0.0685 | Train Acc: 0.9753 | Val Loss: 0.1809 | Val Acc: 0.9384 | Test Loss: 0.2055 | Test Acc: 0.9290\n",
      "No improvement in validation loss. Early stopping counter: 2/2\n",
      "⏹️ Early stopping triggered at epoch 7.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs64_lr5e-06_pat2.json\n",
      "\n",
      "🔄 Tuning with Batch Size: 64, Learning Rate: 5e-06, Patience: 3\n",
      "\n",
      "🔄 Fine-tuning mini_cnn_model...\n",
      "✅ mini_cnn_model loaded successfully from: ../models/all_models/mini_cnn_model_weights.pth\n",
      "🔧 Loaded mini_cnn_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04125f3d778a47f98d5ceb162975a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1541 | Train Acc: 0.9435 | Val Loss: 0.2261 | Val Acc: 0.9185 | Test Loss: 0.2538 | Test Acc: 0.9110\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1449 | Train Acc: 0.9475 | Val Loss: 0.2235 | Val Acc: 0.9197 | Test Loss: 0.2517 | Test Acc: 0.9114\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1427 | Train Acc: 0.9489 | Val Loss: 0.2225 | Val Acc: 0.9206 | Test Loss: 0.2512 | Test Acc: 0.9124\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1413 | Train Acc: 0.9491 | Val Loss: 0.2218 | Val Acc: 0.9215 | Test Loss: 0.2507 | Test Acc: 0.9122\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.1402 | Train Acc: 0.9493 | Val Loss: 0.2214 | Val Acc: 0.9215 | Test Loss: 0.2505 | Test Acc: 0.9126\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.1393 | Train Acc: 0.9496 | Val Loss: 0.2211 | Val Acc: 0.9217 | Test Loss: 0.2503 | Test Acc: 0.9121\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 7 | Train Loss: 0.1385 | Train Acc: 0.9496 | Val Loss: 0.2209 | Val Acc: 0.9215 | Test Loss: 0.2503 | Test Acc: 0.9124\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 8 | Train Loss: 0.1378 | Train Acc: 0.9500 | Val Loss: 0.2207 | Val Acc: 0.9216 | Test Loss: 0.2502 | Test Acc: 0.9127\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 8.\n",
      "✅ Results saved for mini_cnn_model at ../results/fine_tuning_results/mini_cnn_model_bs64_lr5e-06_pat3.json\n",
      "\n",
      "🔄 Fine-tuning tiny_vgg_model...\n",
      "✅ tiny_vgg_model loaded successfully from: ../models/all_models/tiny_vgg_model_weights.pth\n",
      "🔧 Loaded tiny_vgg_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99443508b4c4d0eb48891a45542cd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1802 | Train Acc: 0.9345 | Val Loss: 0.2336 | Val Acc: 0.9166 | Test Loss: 0.2589 | Test Acc: 0.9071\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.1704 | Train Acc: 0.9385 | Val Loss: 0.2284 | Val Acc: 0.9186 | Test Loss: 0.2532 | Test Acc: 0.9091\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.1668 | Train Acc: 0.9405 | Val Loss: 0.2263 | Val Acc: 0.9201 | Test Loss: 0.2510 | Test Acc: 0.9104\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.1650 | Train Acc: 0.9414 | Val Loss: 0.2252 | Val Acc: 0.9200 | Test Loss: 0.2499 | Test Acc: 0.9107\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 5 | Train Loss: 0.1636 | Train Acc: 0.9415 | Val Loss: 0.2245 | Val Acc: 0.9206 | Test Loss: 0.2494 | Test Acc: 0.9105\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 6 | Train Loss: 0.1626 | Train Acc: 0.9420 | Val Loss: 0.2240 | Val Acc: 0.9208 | Test Loss: 0.2490 | Test Acc: 0.9115\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 7 | Train Loss: 0.1618 | Train Acc: 0.9422 | Val Loss: 0.2236 | Val Acc: 0.9209 | Test Loss: 0.2487 | Test Acc: 0.9112\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 8 | Train Loss: 0.1610 | Train Acc: 0.9425 | Val Loss: 0.2232 | Val Acc: 0.9209 | Test Loss: 0.2484 | Test Acc: 0.9114\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 9 | Train Loss: 0.1603 | Train Acc: 0.9429 | Val Loss: 0.2229 | Val Acc: 0.9208 | Test Loss: 0.2479 | Test Acc: 0.9117\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 10 | Train Loss: 0.1598 | Train Acc: 0.9430 | Val Loss: 0.2227 | Val Acc: 0.9208 | Test Loss: 0.2479 | Test Acc: 0.9116\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "✅ Results saved for tiny_vgg_model at ../results/fine_tuning_results/tiny_vgg_model_bs64_lr5e-06_pat3.json\n",
      "\n",
      "🔄 Fine-tuning resnet_model...\n",
      "✅ resnet_model loaded successfully from: ../models/all_models/resnet_model_weights.pth\n",
      "🔧 Loaded resnet_model and set up optimizer with learning rate: 5e-06\n",
      "\n",
      "🔓 Unfreezing certain layers for fine-tuning...\n",
      "✅ Layers unfrozen successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dca540d22c4d2d8bd2fe91fc9a0c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.1011 | Train Acc: 0.9636 | Val Loss: 0.1890 | Val Acc: 0.9326 | Test Loss: 0.2149 | Test Acc: 0.9239\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 2 | Train Loss: 0.0869 | Train Acc: 0.9688 | Val Loss: 0.1835 | Val Acc: 0.9352 | Test Loss: 0.2090 | Test Acc: 0.9260\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 3 | Train Loss: 0.0805 | Train Acc: 0.9710 | Val Loss: 0.1820 | Val Acc: 0.9360 | Test Loss: 0.2075 | Test Acc: 0.9268\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 4 | Train Loss: 0.0771 | Train Acc: 0.9725 | Val Loss: 0.1812 | Val Acc: 0.9369 | Test Loss: 0.2068 | Test Acc: 0.9278\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 5 | Train Loss: 0.0736 | Train Acc: 0.9740 | Val Loss: 0.1807 | Val Acc: 0.9374 | Test Loss: 0.2057 | Test Acc: 0.9280\n",
      "✅ Improvement in validation loss. Best model weights updated.\n",
      "Epoch: 6 | Train Loss: 0.0708 | Train Acc: 0.9749 | Val Loss: 0.1810 | Val Acc: 0.9371 | Test Loss: 0.2059 | Test Acc: 0.9290\n",
      "No improvement in validation loss. Early stopping counter: 1/3\n",
      "Epoch: 7 | Train Loss: 0.0685 | Train Acc: 0.9757 | Val Loss: 0.1813 | Val Acc: 0.9382 | Test Loss: 0.2062 | Test Acc: 0.9289\n",
      "No improvement in validation loss. Early stopping counter: 2/3\n",
      "Epoch: 8 | Train Loss: 0.0664 | Train Acc: 0.9766 | Val Loss: 0.1814 | Val Acc: 0.9384 | Test Loss: 0.2063 | Test Acc: 0.9296\n",
      "No improvement in validation loss. Early stopping counter: 3/3\n",
      "⏹️ Early stopping triggered at epoch 8.\n",
      "✅ Results saved for resnet_model at ../results/fine_tuning_results/resnet_model_bs64_lr5e-06_pat3.json\n",
      "\n",
      "🎉 Hyperparameter Tuning Completed!\n",
      "Best Model: resnet_model\n",
      "Best Validation Accuracy: 0.9397\n",
      "Best Hyperparameters (Batch Size, Learning Rate, Patience): (32, 1e-05, 3)\n",
      "✅ Best model weights saved to: ../models/best_model_weights/best_model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from utils import train_step, validation_step, test_step\n",
    "# Helper function to create and load a model\n",
    "def get_model_and_optimizer(model_class, model_name, learning_rate, hidden_units=20):\n",
    "    \"\"\"\n",
    "    Initializes the model, loads pre-trained weights, and sets up the optimizer.\n",
    "    \"\"\"\n",
    "    model = load_model(model_class, model_name)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"🔧 Loaded {model_name} and set up optimizer with learning rate: {learning_rate}\")\n",
    "    return model, optimizer\n",
    "\n",
    "# Helper function to fine-tune a given model\n",
    "def fine_tune_and_evaluate(model, optimizer, train_loader, val_loader, test_loader, patience):\n",
    "    \"\"\"\n",
    "    Fine-tunes the model and returns the fine-tuning results.\n",
    "    \"\"\"\n",
    "    return fine_tune_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        test_dataloader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        device=device,\n",
    "        patience=patience,\n",
    "        min_delta=0.001,\n",
    "        unfreeze_layers=True\n",
    "    )\n",
    "\n",
    "# Initialize a dictionary to store the best results\n",
    "best_results = {\n",
    "    \"model_name\": None,\n",
    "    \"best_val_acc\": 0.0,\n",
    "    \"best_params\": None,\n",
    "    \"best_model\": None\n",
    "}\n",
    "\n",
    "# Directory to save fine-tuning results\n",
    "results_dir = \"../results/fine_tuning_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for batch_size, learning_rate, patience in product(BATCH_SIZES, LEARNING_RATES, PATIENCE_VALUES):\n",
    "    print(f\"\\n🔄 Tuning with Batch Size: {batch_size}, Learning Rate: {learning_rate}, Patience: {patience}\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(batch_size)\n",
    "\n",
    "    # List of models to fine-tune\n",
    "    model_configs = [\n",
    "        (MiniCNN, \"mini_cnn_model\", learning_rate),\n",
    "        (TinyVGG, \"tiny_vgg_model\", learning_rate),\n",
    "        (ResNet, \"resnet_model\", learning_rate)\n",
    "    ]\n",
    "\n",
    "    # Loop through each model configuration\n",
    "    for model_class, model_name, lr in model_configs:\n",
    "        print(f\"\\n🔄 Fine-tuning {model_name}...\")\n",
    "\n",
    "        # Get model and optimizer\n",
    "        model, optimizer = get_model_and_optimizer(model_class, model_name, lr)\n",
    "\n",
    "        # Fine-tune the model\n",
    "        results = fine_tune_and_evaluate(model, optimizer, train_loader, val_loader, test_loader, patience)\n",
    "\n",
    "        # Save results to JSON file\n",
    "        json_filename = f\"{model_name}_bs{batch_size}_lr{learning_rate}_pat{patience}.json\"\n",
    "        json_path = os.path.join(results_dir, json_filename)\n",
    "        \n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(results, json_file, indent=4)\n",
    "\n",
    "        print(f\"✅ Results saved for {model_name} at {json_path}\")\n",
    "\n",
    "        # Check if this is the best result\n",
    "        if results[\"val_acc\"][-1] > best_results[\"best_val_acc\"]:\n",
    "            best_results[\"model_name\"] = model_name\n",
    "            best_results[\"best_val_acc\"] = results[\"val_acc\"][-1]\n",
    "            best_results[\"best_params\"] = (batch_size, learning_rate, patience)\n",
    "            best_results[\"best_model\"] = model.state_dict()\n",
    "\n",
    "# Summary of Best Results\n",
    "print(\"\\n🎉 Hyperparameter Tuning Completed!\")\n",
    "print(f\"Best Model: {best_results['model_name']}\")\n",
    "print(f\"Best Validation Accuracy: {best_results['best_val_acc']:.4f}\")\n",
    "print(f\"Best Hyperparameters (Batch Size, Learning Rate, Patience): {best_results['best_params']}\")\n",
    "\n",
    "# Save the best model weights\n",
    "best_model_path = \"../models/best_model_weights/best_model_weights.pth\"\n",
    "torch.save(best_results[\"best_model\"], best_model_path)\n",
    "print(f\"✅ Best model weights saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789652c-83f6-44a0-8b33-3bf4599cea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envf)",
   "language": "python",
   "name": "envf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
